name : VAD
version: 1.0.0

external_path:
    - load_train_data_path: ./solution/sample_data/train/
    - load_inference_data_path: ./solution/sample_data/inference/ 
    - save_train_artifacts_path:
    - save_inference_artifacts_path:
    - load_model_path: 

external_path_permission:
    - aws_key_profile:

user_parameters:
    - train_pipeline:
        - step: input  
          args:
            - file_type: csv   
              encoding: utf-8  

        - step: readiness 
          args:
            - y_column: label # (str), label column name | label(default)
              path_column: image_path # (str), image path column name | image_path(default)
              ok_class: # (str), ok class name | blank(default)
              train_validate_column:  # (str), column name | blank(default)
              validation_split_rate: 0.2 # (float), 0<arg<1
              threshold_method: F1 # (str) Percentile | F1(default)
              num_minor_threshold: 5 # (int), 0<arg<100
              ratio_minor_threshold: 0.1 # (float), 0<arg<1
             
        - step: train
          args:
            - model_name: patchcore # (str), patchcore | fastflow
              experiment_seed: 42 # (int), 0<arg<1000
              img_size: 256 # (int), 32<arg
              batch_size: 8 # (int), 1<arg<64
              max_epochs: 30 # (int), 1<arg<1000
              accelerator: gpu # (str), cpu | gpu
              monitor_metric: loss # (str), loss | image_AUROC | image_F1Score
              save_validation_heatmap: True # (bool), True(default) | False
              percentile: 0.9 # (float), 0~1
              augmentation_list: [rotation, brightness, contrast, saturation, hue, blur]
              augmentation_choice: 6
              rotation_angle: 30
              brightness_degree: 0.7
              contrast_degree: 0.7
              saturation_degree: 0.7
              hue_degree: 0.5
              blur_kernel_size: 5
              model_parameters: {“fastflow_backborn”: ‘resnet18’, “fastflow_flow_steps”: 8, “patchcore_backborn”: ‘wide_resnet50_2’, “patchcore_coreset_sampling_ratio”: 0.1, “patchcore_layers”: [“layer2”, “layer3”]}

          ui_args:
            - model_name

    - inference_pipeline:
        - step: input 
          args:
            - file_type: csv   
              encoding: utf-8  

        - step: readiness 
          args:              
             
        - step: inference
          args:
            - save_anomaly_maps: True
              inference_threshold: 0.5 # (float), 0~1
              

        - step: output
          args:
            - none:

asset_source:
    - train_pipeline:
        - step: input
          source:  
            code: https://github.com/mellerikat-aicontents/input.git # (str), local
            branch: v4.1.0_vision
            requirements:
              - pillow
        
        - step: readiness
          source:  
            code: https://github.com/mellerikat-aicontents/readiness.git # (str), git url | local
            branch: v1.0.0_vad
            requirements:

        - step: train
          source: 
            code: https://github.com/mellerikat-aicontents/vad_modeling.git # (str), git url | local
            branch: v1.0.0
            requirements:
              - torch==2.1.2 # --index-url https://download.pytorch.org/whl/cu118 # use for GPU setting
              - torchvision==0.16.2 # --index-url https://download.pytorch.org/whl/cu118 # use for GPU setting
              - requirements.txt

    - inference_pipeline:
        - step: input
          source:  
            code: https://github.com/mellerikat-aicontents/input.git # (str), git url | local
            branch: v4.1.0_vision
            requirements:
              - pillow
              - pandas

        - step: readiness
          source:  
            code: https://github.com/mellerikat-aicontents/readiness.git # (str), git url | local
            branch: v1.0.0_vad
            requirements:

        - step: inference
          source: 
            code: https://github.com/mellerikat-aicontents/vad_modeling.git # (str), git url | local
            branch: v1.0.0
            requirements:

        - step: output
          source:
            code: https://github.com/mellerikat-aicontents/output.git # (str), git url | local
            branch: v1.0.0
            requirements:
              - pillow

control:
  - get_asset_source: every # (str), once | every(default)
  - backup_artifacts: True # (bool), True(default) | False
  - backup_log: True # (bool), True(default) | False
  - backup_size: 1000 # (int), 1000(default) <= args < 10000
  - interface_mode: memory # (str), memory(default) | file
    ## 5. asset data, config interfacing method - memory: (fast) / file: (saved; non-volatilizing)
  # - save_inference_format: tar.gz ## tar.gz, zip
  - check_resource: False ## (bool, str), True(measure memory) | False(default) | cpu
  
ui_args_detail:
    - train_pipeline:

        - step: train
          args:
              - name: model_name
                description: Select a model name to use in VAD.
                type: single_selection
                selectable:
                  - fastflow
                  - patchcore
                default:
                  - fastflow 
  
